{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSCI 4253 / 5253 - Lab #4 - Patent Problem with Spark DataFrames\n",
    "<div>\n",
    " <h2> CSCI 4283 / 5253 \n",
    "  <IMG SRC=\"https://www.colorado.edu/cs/profiles/express/themes/cuspirit/logo.png\" WIDTH=50 ALIGN=\"right\"/> </h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This [Spark cheatsheet](https://s3.amazonaws.com/assets.datacamp.com/blog_assets/PySpark_SQL_Cheat_Sheet_Python.pdf) is useful as is [this reference on doing joins in Spark dataframe](http://www.learnbymarketing.com/1100/pyspark-joins-by-example/).\n",
    "\n",
    "The [DataBricks company has one of the better reference manuals for PySpark](https://docs.databricks.com/spark/latest/dataframes-datasets/index.html) -- they show you how to perform numerous common data operations such as joins, aggregation operations following `groupBy` and the like."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assignment Collaborated with Tanmai Gajula(tanmai.gajula@colorado.edu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following aggregation functions may be useful -- [these can be used to aggregate results of `groupby` operations](https://docs.databricks.com/spark/latest/dataframes-datasets/introduction-to-dataframes-python.html#example-aggregations-using-agg-and-countdistinct). More documentation is at the [PySpark SQL Functions manual](https://spark.apache.org/docs/2.3.0/api/python/pyspark.sql.html#module-pyspark.sql.functions). Feel free to use other functions from that library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, count, countDistinct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create spark session as seen in the tutorials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Lab4-Dataframe\") \\\n",
    "    .master(\"local[*]\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The above statement reads the citation data which is actually not loaded untill it encounters an action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "citations = spark.read.load('cite75_99.txt.gz',\n",
    "            format=\"csv\", sep=\",\", header=True,\n",
    "            compression=\"gzip\",\n",
    "            inferSchema=\"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "| CITING|  CITED|\n",
      "+-------+-------+\n",
      "|3858241| 956203|\n",
      "|3858241|1324234|\n",
      "|3858241|3398406|\n",
      "|3858241|3557384|\n",
      "|3858241|3634889|\n",
      "+-------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "citations.show(5) # This is an Action which means that This is when the data is loaded and the first 5 rows are returned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The above statement reads the patents data which is actually not loaded untill it encounters an action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "patents = spark.read.load('apat63_99.txt.gz',\n",
    "            format=\"csv\", sep=\",\", header=True,\n",
    "            compression=\"gzip\",\n",
    "            inferSchema=\"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+-----+-------+-------+-------+--------+-------+------+------+---+------+-----+--------+--------+-------+--------+--------+--------+--------+--------+--------+--------+\n",
      "| PATENT|GYEAR|GDATE|APPYEAR|COUNTRY|POSTATE|ASSIGNEE|ASSCODE|CLAIMS|NCLASS|CAT|SUBCAT|CMADE|CRECEIVE|RATIOCIT|GENERAL|ORIGINAL|FWDAPLAG|BCKGTLAG|SELFCTUB|SELFCTLB|SECDUPBD|SECDLWBD|\n",
      "+-------+-----+-----+-------+-------+-------+--------+-------+------+------+---+------+-----+--------+--------+-------+--------+--------+--------+--------+--------+--------+--------+\n",
      "|3070801| 1963| 1096|   null|     BE|   null|    null|      1|  null|   269|  6|    69| null|       1|    null|    0.0|    null|    null|    null|    null|    null|    null|    null|\n",
      "|3070802| 1963| 1096|   null|     US|     TX|    null|      1|  null|     2|  6|    63| null|       0|    null|   null|    null|    null|    null|    null|    null|    null|    null|\n",
      "|3070803| 1963| 1096|   null|     US|     IL|    null|      1|  null|     2|  6|    63| null|       9|    null| 0.3704|    null|    null|    null|    null|    null|    null|    null|\n",
      "|3070804| 1963| 1096|   null|     US|     OH|    null|      1|  null|     2|  6|    63| null|       3|    null| 0.6667|    null|    null|    null|    null|    null|    null|    null|\n",
      "|3070805| 1963| 1096|   null|     US|     CA|    null|      1|  null|     2|  6|    63| null|       1|    null|    0.0|    null|    null|    null|    null|    null|    null|    null|\n",
      "+-------+-----+-----+-------+-------+-------+--------+-------+------+------+---+------+-----+--------+--------+-------+--------+--------+--------+--------+--------+--------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "patents.show(5) # This is an Action which means that This is when the data is loaded and the first 5 rows are returned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select PATENT and POSTATE columns from patents dataframe and assign it to new dataframe: df [Transformation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = patents.select(\"PATENT\", \"POSTATE\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we cache the pysaprk dataframe which is also a lazy operation - and is actually triggered when we encounter an action later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[PATENT: int, POSTATE: string]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we Perform left join on citations pyspark dataframe and df with citations.CITING == df.PATENT, and drop PATENT column from result and rename POSTATE column to CITING_STATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = citations.join(df, citations.CITING == df.PATENT, 'left').drop(\"PATENT\").withColumnRenamed(\"POSTATE\", \"CITING_STATE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------------+\n",
      "| CITING|  CITED|CITING_STATE|\n",
      "+-------+-------+------------+\n",
      "|3858258|1331793|          CA|\n",
      "|3858258|1540798|          CA|\n",
      "|3858527| 924225|        null|\n",
      "|3858527|2444326|        null|\n",
      "|3858527|2705120|        null|\n",
      "+-------+-------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show(5) # This action computes all the transformations and displays result of first 5 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we do Left join with the intermediate table df1 and df with df1.CITED == df.PATENT and rename POSTATE column to CITED_STATE which is a transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df1.join(df, df1.CITED == df.PATENT, 'left').drop(\"PATENT\").withColumnRenamed(\"POSTATE\", \"CITED_STATE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+------------+-----------+\n",
      "| CITING|CITED|CITING_STATE|CITED_STATE|\n",
      "+-------+-----+------------+-----------+\n",
      "|4305315| 2366|          MN|       null|\n",
      "|4192521| 2366|        null|       null|\n",
      "|4253355| 2366|          MN|       null|\n",
      "|5580635| 5156|          WI|       null|\n",
      "|4976561| 5518|        null|       null|\n",
      "+-------+-----+------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show(5) # In the next action now the previous transformations on this dataframe are computed and the first 5 rows of resultant\n",
    "#dataframe are displayed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter out NULL entried from CITING_STATE and CITED_STATE columns from dataframe df2 [Transformation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2.filter(\"CITING_STATE is not Null and CITED_STATE is not Null\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------------+-----------+\n",
      "| CITING|  CITED|CITING_STATE|CITED_STATE|\n",
      "+-------+-------+------------+-----------+\n",
      "|4496943|3071753|          NJ|         MN|\n",
      "|4345315|3071753|          TN|         MN|\n",
      "|4120573|3071753|          IL|         MN|\n",
      "|3949375|3071753|          NJ|         MN|\n",
      "|4271479|3071753|          NY|         MN|\n",
      "|4280448|3072100|          KS|         IL|\n",
      "|3861359|3072100|          IL|         IL|\n",
      "|4138968|3072100|          KS|         IL|\n",
      "|3894516|3072100|          OK|         IL|\n",
      "|4572109|3072100|          SC|         IL|\n",
      "|4396343|3072274|          OH|         WI|\n",
      "|4955781|3072274|          OR|         WI|\n",
      "|4907934|3072274|          OR|         WI|\n",
      "|3917094|3072274|          WI|         WI|\n",
      "|3908563|3073661|          CT|         IL|\n",
      "|4615276|3073661|          RI|         IL|\n",
      "|5926985|3073661|          MI|         IL|\n",
      "|4546302|3074006|          MN|         CA|\n",
      "|4720941|3074211|          FL|         MA|\n",
      "|3947152|3075459|          NY|         OH|\n",
      "+-------+-------+------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.show() # In this action, The filter transformation is now applied and the resultant dataframe with non null entries in both\n",
    "# CITING_STATE and CITED_STATE are returned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now weaApply filter tranformation to take subset of dataframe where CITING_STATE == CITED_STATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df3.filter(\"CITING_STATE == CITED_STATE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------------+-----------+\n",
      "| CITING|  CITED|CITING_STATE|CITED_STATE|\n",
      "+-------+-------+------------+-----------+\n",
      "|4383847|3177062|          AL|         AL|\n",
      "|3878730|3610053|          AL|         AL|\n",
      "|3877317|3610053|          AL|         AL|\n",
      "|4601891|3733191|          AL|         AL|\n",
      "|4237106|3733191|          AL|         AL|\n",
      "|4028087|3733191|          AL|         AL|\n",
      "|4427432|3969483|          AL|         AL|\n",
      "|4246248|3969483|          AL|         AL|\n",
      "|4090893|3974004|          AL|         AL|\n",
      "|4429634|3974004|          AL|         AL|\n",
      "|4471988|4415080|          AL|         AL|\n",
      "|4725766|4546264|          AL|         AL|\n",
      "|4730154|4546264|          AL|         AL|\n",
      "|4735382|4546264|          AL|         AL|\n",
      "|5049030|4547115|          AL|         AL|\n",
      "|4880701|4698246|          AL|         AL|\n",
      "|4806399|4698246|          AL|         AL|\n",
      "|5213858|4698246|          AL|         AL|\n",
      "|4888222|4698246|          AL|         AL|\n",
      "|4983431|4698246|          AL|         AL|\n",
      "+-------+-------+------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4.show() # This Action Filter transformation is computed and returned dataframe contains records where CITING_STATE == CITED_STATE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will grouby CITING and perform aggregate function - count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = df4.drop(\"CITED\", \"CITING_STATE\", \"CITED_STATE\").groupby(\"CITING\").count() # Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "| CITING|count|\n",
      "+-------+-----+\n",
      "|4214280|    2|\n",
      "|4712293|    5|\n",
      "|5968543|    8|\n",
      "|5723969|    4|\n",
      "|5279657|    2|\n",
      "|5489298|   16|\n",
      "|5354420|    1|\n",
      "|5976783|    5|\n",
      "|4899423|    1|\n",
      "|5550181|    5|\n",
      "+-------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df5.show(10) # In this action it  Computes the earlier transformation and returns result of groupby with count."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we perform a left join of patents dataframe with df5 on patents.PATENT == df5.CITING and we drop CITING column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6 = patents.join(df5, patents.PATENT == df5.CITING, 'left').drop(\"CITING\") # Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next fill the NULL values in count column in df6 with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6 = df6.na.fill({'count': 0}) # Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next Transformation we use orderby count column in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df7 = df6.orderBy('count', ascending=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next action displays the first 10 records of dataframe sorted in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+-----+-------+-------+-------+--------+-------+------+------+---+------+-----+--------+--------+-------+--------+--------+--------+--------+--------+--------+--------+-----+\n",
      "| PATENT|GYEAR|GDATE|APPYEAR|COUNTRY|POSTATE|ASSIGNEE|ASSCODE|CLAIMS|NCLASS|CAT|SUBCAT|CMADE|CRECEIVE|RATIOCIT|GENERAL|ORIGINAL|FWDAPLAG|BCKGTLAG|SELFCTUB|SELFCTLB|SECDUPBD|SECDLWBD|count|\n",
      "+-------+-----+-----+-------+-------+-------+--------+-------+------+------+---+------+-----+--------+--------+-------+--------+--------+--------+--------+--------+--------+--------+-----+\n",
      "|5959466| 1999|14515|   1997|     US|     CA|    5310|      2|  null|   326|  4|    46|  159|       0|     1.0|   null|  0.6186|    null|  4.8868|  0.0455|   0.044|    null|    null|  125|\n",
      "|5983822| 1999|14564|   1998|     US|     TX|  569900|      2|  null|   114|  5|    55|  200|       0|   0.995|   null|  0.7201|    null|   12.45|     0.0|     0.0|    null|    null|  103|\n",
      "|6008204| 1999|14606|   1998|     US|     CA|  749584|      2|  null|   514|  3|    31|  121|       0|     1.0|   null|  0.7415|    null|     5.0|  0.0085|  0.0083|    null|    null|  100|\n",
      "|5952345| 1999|14501|   1997|     US|     CA|  749584|      2|  null|   514|  3|    31|  118|       0|     1.0|   null|  0.7442|    null|  5.1102|     0.0|     0.0|    null|    null|   98|\n",
      "|5958954| 1999|14515|   1997|     US|     CA|  749584|      2|  null|   514|  3|    31|  116|       0|     1.0|   null|  0.7397|    null|   5.181|     0.0|     0.0|    null|    null|   96|\n",
      "|5998655| 1999|14585|   1998|     US|     CA|    null|      1|  null|   560|  1|    14|  114|       0|     1.0|   null|  0.7387|    null|  5.1667|    null|    null|    null|    null|   96|\n",
      "|5936426| 1999|14466|   1997|     US|     CA|    5310|      2|  null|   326|  4|    46|  178|       0|     1.0|   null|    0.58|    null| 11.2303|  0.0765|   0.073|    null|    null|   94|\n",
      "|5739256| 1998|13983|   1995|     US|     CA|   70060|      2|    15|   528|  1|    15|  453|       0|     1.0|   null|  0.8232|    null| 15.1104|  0.1124|  0.1082|    null|    null|   90|\n",
      "|5925042| 1999|14445|   1997|     US|     CA|  733846|      2|  null|   606|  3|    32|  242|       0|     1.0|   null|  0.7382|    null|  8.3471|     0.0|     0.0|    null|    null|   90|\n",
      "|5978329| 1999|14550|   1995|     US|     CA|  148925|      2|  null|   369|  2|    24|  145|       0|     1.0|   null|  0.5449|    null| 12.9241|  0.4196|  0.4138|    null|    null|   90|\n",
      "+-------+-----+-----+-------+-------+-------+--------+-------+------+------+---+------+-----+--------+--------+-------+--------+--------+--------+--------+--------+--------+--------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df7.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
